"""
Business KPI Tracking and ROI Analysis
======================================

Tracks business-aligned KPIs and calculates ROI for ML models.
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Union, Callable
from dataclasses import dataclass, field
import logging
from datetime import datetime
import json
import yaml
from pathlib import Path

@dataclass
class KPIDefinition:
    """Definition of a business KPI"""
    name: str
    description: str
    calculation_method: str  # 'direct', 'formula', 'function'
    formula: Optional[str] = None
    weight: float = 1.0
    target_value: Optional[float] = None
    threshold_warning: Optional[float] = None
    threshold_critical: Optional[float] = None
    unit: str = ""
    higher_is_better: bool = True
    category: str = "general"  # 'revenue', 'cost', 'satisfaction', 'operational'

@dataclass
class KPIResult:
    """Result of KPI calculation"""
    kpi_name: str
    value: float
    target_value: Optional[float]
    achievement_rate: Optional[float]
    status: str  # 'excellent', 'good', 'warning', 'critical'
    impact_score: float
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())

@dataclass
class ROIAnalysis:
    """ROI analysis results"""
    total_investment: float
    total_benefit: float
    net_benefit: float
    roi_percentage: float
    payback_period_months: Optional[float]
    npv: Optional[float]
    irr: Optional[float]
    cost_breakdown: Dict[str, float] = field(default_factory=dict)
    benefit_breakdown: Dict[str, float] = field(default_factory=dict)
    assumptions: Dict[str, Any] = field(default_factory=dict)

class BusinessKPITracker:
    """
    Tracks business KPIs and calculates ROI for ML initiatives
    """
    
    def __init__(self, config_file: str = "config/business_kpis.yaml"):
        self.config_file = config_file
        self.kpi_definitions = {}
        self.kpi_history = []
        self.roi_calculations = []
        self.business_context = {}
        
        self.logger = logging.getLogger(__name__)
        self._load_kpi_definitions()
    
    def _load_kpi_definitions(self):
        """Load KPI definitions from configuration file"""
        config_path = Path(self.config_file)
        
        if config_path.exists():
            try:
                with open(config_path, 'r') as f:
                    config = yaml.safe_load(f)
                
                kpis_config = config.get('kpis', {})
                for kpi_name, kpi_data in kpis_config.items():
                    # Add the name to the kpi_data if not present
                    if 'name' not in kpi_data:
                        kpi_data['name'] = kpi_name
                    kpi = KPIDefinition(**kpi_data)
                    self.kpi_definitions[kpi.name] = kpi
                
                self.business_context = config.get('business_context', {})
                self.logger.info(f"Loaded {len(self.kpi_definitions)} KPI definitions")
                
            except Exception as e:
                self.logger.error(f"Failed to load KPI definitions: {e}")
                self._create_default_kpis()
        else:
            self.logger.info("No KPI config file found, creating default KPIs")
            self._create_default_kpis()
    
    def _create_default_kpis(self):
        """Create default KPI definitions"""
        default_kpis = [
            KPIDefinition(
                name="model_accuracy",
                description="Model prediction accuracy",
                calculation_method="direct",
                weight=0.3,
                target_value=0.85,
                threshold_warning=0.8,
                threshold_critical=0.7,
                unit="ratio",
                category="operational"
            ),
            KPIDefinition(
                name="false_positive_cost",
                description="Cost of false positive predictions",
                calculation_method="formula",
                formula="false_positives * cost_per_fp",
                weight=0.25,
                higher_is_better=False,
                unit="currency",
                category="cost"
            ),
            KPIDefinition(
                name="true_positive_value",
                description="Value generated by true positive predictions",
                calculation_method="formula", 
                formula="true_positives * value_per_tp",
                weight=0.25,
                higher_is_better=True,
                unit="currency",
                category="revenue"
            ),
            KPIDefinition(
                name="customer_satisfaction",
                description="Customer satisfaction score",
                calculation_method="direct",
                weight=0.2,
                target_value=4.5,
                threshold_warning=4.0,
                threshold_critical=3.5,
                unit="score",
                category="satisfaction"
            )
        ]
        
        for kpi in default_kpis:
            self.kpi_definitions[kpi.name] = kpi
    
    def calculate_kpis(self, ml_results: Dict[str, Any], 
                      business_data: Dict[str, Any] = None) -> Dict[str, KPIResult]:
        """
        Calculate all defined KPIs
        
        Args:
            ml_results: ML model results (predictions, metrics, etc.)
            business_data: Additional business context data
            
        Returns:
            Dictionary of KPI results
        """
        kpi_results = {}
        context = {**self.business_context, **(business_data or {}), **ml_results}
        
        for kpi_name, kpi_def in self.kpi_definitions.items():
            try:
                result = self._calculate_single_kpi(kpi_def, context)
                kpi_results[kpi_name] = result
                self.kpi_history.append(result)
                
            except Exception as e:
                self.logger.error(f"Failed to calculate KPI {kpi_name}: {e}")
                kpi_results[kpi_name] = KPIResult(
                    kpi_name=kpi_name,
                    value=0.0,
                    target_value=kpi_def.target_value,
                    achievement_rate=0.0,
                    status="error",
                    impact_score=0.0,
                    metadata={"error": str(e)}
                )
        
        return kpi_results
    
    def _calculate_single_kpi(self, kpi_def: KPIDefinition, 
                            context: Dict[str, Any]) -> KPIResult:
        """Calculate a single KPI"""
        
        if kpi_def.calculation_method == "direct":
            value = context.get(kpi_def.name, 0.0)
            
        elif kpi_def.calculation_method == "formula":
            value = self._evaluate_formula(kpi_def.formula, context)
            
        elif kpi_def.calculation_method == "function":
            # For custom functions - would need to be implemented
            value = 0.0
            
        else:
            raise ValueError(f"Unknown calculation method: {kpi_def.calculation_method}")
        
        # Calculate achievement rate
        achievement_rate = None
        if kpi_def.target_value is not None:
            if kpi_def.higher_is_better:
                achievement_rate = value / kpi_def.target_value
            else:
                achievement_rate = kpi_def.target_value / value if value > 0 else 0
        
        # Determine status
        status = self._determine_kpi_status(value, kpi_def)
        
        # Calculate impact score (weighted value)
        impact_score = value * kpi_def.weight
        
        return KPIResult(
            kpi_name=kpi_def.name,
            value=value,
            target_value=kpi_def.target_value,
            achievement_rate=achievement_rate,
            status=status,
            impact_score=impact_score,
            metadata={
                "calculation_method": kpi_def.calculation_method,
                "weight": kpi_def.weight,
                "category": kpi_def.category
            }
        )
    
    def _evaluate_formula(self, formula: str, context: Dict[str, Any]) -> float:
        """Safely evaluate a KPI formula"""
        try:
            # Simple variable substitution
            eval_formula = formula
            for key, value in context.items():
                if isinstance(value, (int, float)):
                    eval_formula = eval_formula.replace(key, str(value))
            
            # Safe evaluation (restricted)
            allowed_names = {
                "__builtins__": {},
                "abs": abs, "min": min, "max": max, 
                "round": round, "sum": sum
            }
            
            return float(eval(eval_formula, allowed_names))
            
        except Exception as e:
            self.logger.warning(f"Formula evaluation failed: {formula}, error: {e}")
            return 0.0
    
    def _determine_kpi_status(self, value: float, kpi_def: KPIDefinition) -> str:
        """Determine KPI status based on thresholds"""
        
        if kpi_def.threshold_critical is not None:
            if kpi_def.higher_is_better:
                if value < kpi_def.threshold_critical:
                    return "critical"
            else:
                if value > kpi_def.threshold_critical:
                    return "critical"
        
        if kpi_def.threshold_warning is not None:
            if kpi_def.higher_is_better:
                if value < kpi_def.threshold_warning:
                    return "warning"
            else:
                if value > kpi_def.threshold_warning:
                    return "warning"
        
        if kpi_def.target_value is not None:
            if kpi_def.higher_is_better:
                if value >= kpi_def.target_value:
                    return "excellent"
                else:
                    return "good"
            else:
                if value <= kpi_def.target_value:
                    return "excellent"
                else:
                    return "good"
        
        return "good"
    
    def calculate_roi(self, investment_data: Dict[str, float],
                     benefit_data: Dict[str, float],
                     time_horizon_months: int = 12) -> ROIAnalysis:
        """
        Calculate ROI analysis for ML initiative
        
        Args:
            investment_data: Dictionary of investment costs
            benefit_data: Dictionary of benefits/savings
            time_horizon_months: Time horizon for analysis
            
        Returns:
            ROI analysis results
        """
        
        total_investment = sum(investment_data.values())
        total_benefit = sum(benefit_data.values())
        net_benefit = total_benefit - total_investment
        
        roi_percentage = (net_benefit / total_investment * 100) if total_investment > 0 else 0
        
        # Simple payback period calculation
        monthly_benefit = total_benefit / time_horizon_months
        payback_period = total_investment / monthly_benefit if monthly_benefit > 0 else None
        
        # NPV calculation (simplified, assuming 10% discount rate)
        discount_rate = 0.10
        monthly_rate = discount_rate / 12
        npv = -total_investment
        
        for month in range(1, time_horizon_months + 1):
            npv += monthly_benefit / ((1 + monthly_rate) ** month)
        
        roi_analysis = ROIAnalysis(
            total_investment=total_investment,
            total_benefit=total_benefit,
            net_benefit=net_benefit,
            roi_percentage=roi_percentage,
            payback_period_months=payback_period,
            npv=npv,
            irr=None,  # IRR calculation is more complex
            cost_breakdown=investment_data.copy(),
            benefit_breakdown=benefit_data.copy(),
            assumptions={
                "time_horizon_months": time_horizon_months,
                "discount_rate": discount_rate,
                "calculation_date": datetime.now().isoformat()
            }
        )
        
        self.roi_calculations.append(roi_analysis)
        return roi_analysis
    
    def calculate_business_ml_correlation(self, ml_metrics: Dict[str, float],
                                        business_metrics: Dict[str, float]) -> Dict[str, float]:
        """
        Calculate correlation between ML metrics and business metrics
        
        Args:
            ml_metrics: Dictionary of ML performance metrics
            business_metrics: Dictionary of business KPI values
            
        Returns:
            Correlation coefficients between ML and business metrics
        """
        correlations = {}
        
        # Convert to arrays for correlation calculation
        ml_values = list(ml_metrics.values())
        business_values = list(business_metrics.values())
        
        if len(ml_values) > 1 and len(business_values) > 1:
            try:
                correlation_matrix = np.corrcoef([ml_values, business_values])
                overall_correlation = correlation_matrix[0, 1] if not np.isnan(correlation_matrix[0, 1]) else 0.0
                correlations['overall_ml_business_correlation'] = overall_correlation
                
            except Exception as e:
                self.logger.warning(f"Failed to calculate overall correlation: {e}")
                correlations['overall_ml_business_correlation'] = 0.0
        
        # Individual metric correlations (would need historical data)
        for ml_metric, ml_value in ml_metrics.items():
            for business_metric, business_value in business_metrics.items():
                corr_key = f"{ml_metric}_vs_{business_metric}"
                # Simplified correlation - in real implementation would use historical data
                correlations[corr_key] = 0.5  # Placeholder
        
        return correlations
    
    def generate_business_report(self, kpi_results: Dict[str, KPIResult],
                               roi_analysis: ROIAnalysis = None) -> Dict[str, Any]:
        """Generate comprehensive business performance report"""
        
        # Aggregate KPI results by category
        category_performance = {}
        for kpi_result in kpi_results.values():
            category = kpi_result.metadata.get('category', 'general')
            if category not in category_performance:
                category_performance[category] = {
                    'total_impact': 0.0,
                    'kpis': [],
                    'average_achievement': 0.0
                }
            
            category_performance[category]['total_impact'] += kpi_result.impact_score
            category_performance[category]['kpis'].append(kpi_result)
        
        # Calculate category averages
        for category, data in category_performance.items():
            achievements = [kpi.achievement_rate for kpi in data['kpis'] 
                          if kpi.achievement_rate is not None]
            data['average_achievement'] = np.mean(achievements) if achievements else 0.0
        
        # Overall business score
        total_impact = sum(kpi.impact_score for kpi in kpi_results.values())
        total_weight = sum(self.kpi_definitions[name].weight for name in kpi_results.keys())
        business_score = total_impact / total_weight if total_weight > 0 else 0.0
        
        report = {
            'summary': {
                'overall_business_score': business_score,
                'total_kpis_tracked': len(kpi_results),
                'kpis_on_target': len([k for k in kpi_results.values() if k.status in ['excellent', 'good']]),
                'kpis_needing_attention': len([k for k in kpi_results.values() if k.status in ['warning', 'critical']]),
                'report_timestamp': datetime.now().isoformat()
            },
            'kpi_results': {name: {
                'value': result.value,
                'target': result.target_value,
                'achievement_rate': result.achievement_rate,
                'status': result.status,
                'impact_score': result.impact_score
            } for name, result in kpi_results.items()},
            'category_performance': category_performance,
            'roi_analysis': roi_analysis.__dict__ if roi_analysis else None,
            'recommendations': self._generate_recommendations(kpi_results, category_performance)
        }
        
        return report
    
    def _generate_recommendations(self, kpi_results: Dict[str, KPIResult],
                                category_performance: Dict[str, Any]) -> List[str]:
        """Generate actionable recommendations based on KPI performance"""
        recommendations = []
        
        # Identify underperforming KPIs
        critical_kpis = [name for name, result in kpi_results.items() 
                        if result.status == 'critical']
        
        if critical_kpis:
            recommendations.append(
                f"URGENT: Address critical KPIs: {', '.join(critical_kpis)}"
            )
        
        warning_kpis = [name for name, result in kpi_results.items() 
                       if result.status == 'warning']
        
        if warning_kpis:
            recommendations.append(
                f"Monitor closely: {', '.join(warning_kpis)} showing warning signs"
            )
        
        # Category-based recommendations
        for category, data in category_performance.items():
            if data['average_achievement'] < 0.8:
                recommendations.append(
                    f"Focus on improving {category} metrics (current achievement: {data['average_achievement']:.1%})"
                )
        
        # ROI-based recommendations
        # (Would be based on ROI analysis if provided)
        
        return recommendations
    
    def save_results(self, output_dir: str = "evaluation_results/business_metrics"):
        """Save KPI and ROI results to files"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Save KPI history
        if self.kpi_history:
            kpi_file = output_path / "kpi_history.json"
            with open(kpi_file, 'w') as f:
                json.dump([result.__dict__ for result in self.kpi_history], f, indent=2)
        
        # Save ROI calculations
        if self.roi_calculations:
            roi_file = output_path / "roi_analysis.json"
            with open(roi_file, 'w') as f:
                json.dump([analysis.__dict__ for analysis in self.roi_calculations], f, indent=2)
        
        self.logger.info(f"Business metrics saved to {output_path}")

# Helper functions for integration
def calculate_business_value(y_true, y_pred, y_prob=None, business_params=None):
    """
    Calculate business value of predictions
    
    Args:
        y_true: True labels
        y_pred: Predicted labels
        y_prob: Prediction probabilities (optional)
        business_params: Dictionary with business parameters
        
    Returns:
        Dictionary with business value metrics
    """
    if business_params is None:
        business_params = {
            'true_positive_value': 100,
            'false_positive_cost': 50,
            'false_negative_cost': 200,
            'true_negative_value': 10
        }
    
    # Calculate confusion matrix values
    from sklearn.metrics import confusion_matrix
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    
    # Calculate business value
    total_value = (
        tp * business_params.get('true_positive_value', 0) +
        tn * business_params.get('true_negative_value', 0) -
        fp * business_params.get('false_positive_cost', 0) -
        fn * business_params.get('false_negative_cost', 0)
    )
    
    return {
        'total_business_value': total_value,
        'true_positives': tp,
        'false_positives': fp,
        'true_negatives': tn,
        'false_negatives': fn,
        'true_positive_value': tp * business_params.get('true_positive_value', 0),
        'false_positive_cost': fp * business_params.get('false_positive_cost', 0),
        'false_negative_cost': fn * business_params.get('false_negative_cost', 0),
        'true_negative_value': tn * business_params.get('true_negative_value', 0)
    }
